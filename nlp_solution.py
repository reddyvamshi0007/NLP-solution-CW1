# -*- coding: utf-8 -*-
"""NLP solution

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TzCTN_yB5h4DMVAajQ91HRWCpQK8mW4C
"""

!pip install wordcloud tensorflow nltk seaborn joblib

import pandas as pd
import numpy as np
import re
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from string import punctuation
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import joblib

# Download NLTK resources
nltk.download("stopwords")
nltk.download("punkt")
nltk.download('punkt_tab')

file_path = "rct_data.txt"
with open(file_path, "r", encoding="utf-8") as f:
    data = f.readlines()

"""## Convert Data into a Pandas DataFrame"""

dataset = []
for line in data:
    parts = line.strip().split("\t")
    if len(parts) == 5:
        dataset.append(parts)

columns = ["PMID", "Label", "Year", "Title", "Abstract"]
df = pd.DataFrame(dataset, columns=columns)

df["Label"] = df["Label"].astype(int)
df["Year"] = df["Year"].astype(int)

print(df.info())
print(df.head())

plt.figure(figsize=(6,4))
sns.countplot(x=df["Label"], palette="pastel")
plt.title("Distribution of RCT vs. Non-RCT Labels")
plt.xlabel("Label (0 = Non-RCT, 1 = RCT)")
plt.ylabel("Count")
plt.show()

rct_text = " ".join(df[df["Label"] == 1]["Abstract"])
non_rct_text = " ".join(df[df["Label"] == 0]["Abstract"])

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(WordCloud(background_color="white").generate(rct_text))
plt.title("WordCloud - RCT Abstracts")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(WordCloud(background_color="white").generate(non_rct_text))
plt.title("WordCloud - Non-RCT Abstracts")
plt.axis("off")

plt.show()

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = text.translate(str.maketrans("", "", punctuation))
    words = word_tokenize(text)
    words = [word for word in words if word not in stopwords.words("english")]
    return " ".join(words)

df["Cleaned_Abstract"] = df["Abstract"].apply(preprocess_text)
print(df[["Abstract", "Cleaned_Abstract"]].head())

"""## Convert Text to TF-IDF Features"""

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df["Cleaned_Abstract"])
y = df["Label"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Training Size: {X_train.shape}, Testing Size: {X_test.shape}")

"""## Train Multiple ML Models"""

# Naïve Bayes Classifier
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

print("Naïve Bayes Results:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}")
print(classification_report(y_test, y_pred_nb))

# Logistic Regression
log_reg_model = LogisticRegression()
log_reg_model.fit(X_train, y_train)
y_pred_lr = log_reg_model.predict(X_test)

print("Logistic Regression Results:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}")
print(classification_report(y_test, y_pred_lr))

"""## CNN-based NLP Model"""

# Tokenize & Pad Sequences
MAX_WORDS = 5000
MAX_LEN = 200

tokenizer = Tokenizer(num_words=MAX_WORDS)
tokenizer.fit_on_texts(df["Cleaned_Abstract"])

X_seq = tokenizer.texts_to_sequences(df["Cleaned_Abstract"])
X_pad = pad_sequences(X_seq, maxlen=MAX_LEN)

X_train_pad, X_test_pad, y_train_pad, y_test_pad = train_test_split(X_pad, y, test_size=0.2, random_state=42, stratify=y)

"""## Build CNN Model"""

cnn_model = Sequential([
    Embedding(input_dim=MAX_WORDS, output_dim=100, input_length=MAX_LEN),
    Conv1D(128, 5, activation="relu"),
    GlobalMaxPooling1D(),
    Dense(64, activation="relu"),
    Dense(1, activation="sigmoid")
])

cnn_model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])
cnn_model.summary()

cnn_model.fit(X_train_pad, y_train_pad, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test_pad))

cnn_loss, cnn_acc = cnn_model.evaluate(X_test_pad, y_test_pad)
print(f"CNN Model Accuracy: {cnn_acc:.4f}")

# Model Performance Visualization
models = ["Naïve Bayes", "Logistic Regression", "CNN"]
accuracies = [
    accuracy_score(y_test, y_pred_nb),
    accuracy_score(y_test, y_pred_lr),
    cnn_acc
]

plt.figure(figsize=(8, 5))
sns.barplot(x=models, y=accuracies, palette="coolwarm")
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy Score")
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay

# Set figure size
plt.figure(figsize=(15, 5))

# Naïve Bayes Confusion Matrix
plt.subplot(1, 3, 1)
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_nb, cmap="Blues", ax=plt.gca())
plt.title("Naïve Bayes Confusion Matrix")

# Logistic Regression Confusion Matrix
plt.subplot(1, 3, 2)
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr, cmap="Greens", ax=plt.gca())
plt.title("Logistic Regression Confusion Matrix")

# CNN Confusion Matrix
plt.subplot(1, 3, 3)
y_pred_cnn = (cnn_model.predict(X_test_pad) > 0.5).astype("int32")  # Convert CNN predictions to binary labels
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_cnn, cmap="Reds", ax=plt.gca())
plt.title("CNN Confusion Matrix")

plt.tight_layout()
plt.show()

from sklearn.metrics import precision_score, recall_score

# Calculate Precision & Recall for each model
precision_scores = [
    precision_score(y_test, y_pred_nb),
    precision_score(y_test, y_pred_lr),
    precision_score(y_test, y_pred_cnn)
]

recall_scores = [
    recall_score(y_test, y_pred_nb),
    recall_score(y_test, y_pred_lr),
    recall_score(y_test, y_pred_cnn)
]

# Create bar plot for Precision & Recall
x_labels = ["Naïve Bayes", "Logistic Regression", "CNN"]
x = np.arange(len(x_labels))

plt.figure(figsize=(8, 5))
plt.bar(x - 0.2, precision_scores, width=0.4, label="Precision", color="skyblue")
plt.bar(x + 0.2, recall_scores, width=0.4, label="Recall", color="salmon")

plt.xticks(x, x_labels)
plt.ylabel("Score")
plt.title("Precision & Recall Comparison")
plt.ylim(0, 1)  # Scores range from 0 to 1
plt.legend()
plt.show()

